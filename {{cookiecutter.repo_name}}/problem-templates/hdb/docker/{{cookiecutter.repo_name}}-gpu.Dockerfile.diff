--- {{cookiecutter.repo_name}}/docker/{{cookiecutter.repo_name}}-gpu.Dockerfile
+++ {{cookiecutter.repo_name}}/problem-templates/hdb/docker/{{cookiecutter.repo_name}}-gpu.Dockerfile
@@ -1,4 +1,41 @@
+# Comment this out if deployed within Run:ai
+FROM nvcr.io/nvidia/cuda:12.6.3-cudnn-devel-ubuntu24.04 AS compile-image
+
+# Use this if deployed outside Run:ai
+FROM python:3.12-slim AS compile-image
+
+ARG DEBIAN_FRONTEND="noninteractive"
+
+ARG NON_ROOT_USER="aisg"
+ARG NON_ROOT_UID="2222"
+ARG NON_ROOT_GID="2222"
+ARG HOME_DIR="/home/${NON_ROOT_USER}"
+
+ARG REPO_DIR="."
+
+RUN useradd -l -m -s /bin/bash -u ${NON_ROOT_UID} ${NON_ROOT_USER}
+
+RUN apt update && \
+    apt -y install curl git build-essential && \
+    apt clean
+
+ENV PYTHONIOENCODING=utf8
+ENV LANG="C.UTF-8"
+ENV LC_ALL="C.UTF-8"
+ENV NVIDIA_VISIBLE_DEVICES=all
+ENV NVIDIA_DRIVER_CAPABILITIES=compute,utility
+ENV LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
+ENV PATH="${HOME_DIR}/.local/bin:${PATH}"
+
+USER ${NON_ROOT_USER}
+WORKDIR ${HOME_DIR}
+
+COPY --chown=${NON_ROOT_USER}:${NON_ROOT_GID} ${REPO_DIR} {{cookiecutter.repo_name}}
+
+# Install pip requirements
+RUN pip install -r {{cookiecutter.repo_name}}/requirements.txt
+
 # Comment this out if deployed within Run:ai
 FROM nvcr.io/nvidia/cuda:12.6.3-cudnn-devel-ubuntu24.04
 
 # Use this if deployed within Run:ai
@@ -32,8 +69,10 @@
 
 USER ${NON_ROOT_USER}
 WORKDIR ${HOME_DIR}
 
+COPY --from=compile-image ${HOME_DIR}/.local ${HOME_DIR}/.local
+
 COPY --chown=${NON_ROOT_USER}:${NON_ROOT_GID} ${REPO_DIR} {{cookiecutter.repo_name}}
 
 # Comment this out if deployed within Run:ai
 RUN micromamba shell init -s bash -r ${HOME_DIR}/micromamba
@@ -42,4 +81,6 @@
 RUN echo 'alias python="micromamba run -n base python"' >> "${HOME_DIR}/.bashrc"
 
 # Use this if deployed outside Run:ai
 #RUN pip install -r {{cookiecutter.repo_name}}/requirements.txt
+
+WORKDIR ${HOME_DIR}/{{cookiecutter.repo_name}}
