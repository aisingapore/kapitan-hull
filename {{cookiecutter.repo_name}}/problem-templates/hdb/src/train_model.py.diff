--- {{cookiecutter.repo_name}}/src/train_model.py
+++ {{cookiecutter.repo_name}}/problem-templates/hdb/src/train_model.py
@@ -1,10 +1,10 @@
 """
-This script is for training a dummy model on a dummy dataset.
+This script is for training a XGBRegressor model on the HDB dataset. Note that
+the script is incomplete and requires you to modify it accordingly to your solution.
 """
 import os
 import logging
-import json
 import omegaconf
 import hydra
 import mlflow
 
@@ -28,43 +28,36 @@
         logging_config_path=os.path.join(
             hydra.utils.get_original_cwd(), "conf", "logging.yaml"
         )
     )
-    logger.info(
-        "Starting training with {} epochs, lr={}, batch_size={}".format(
-            args['epochs'], args['lr'], args['train_bs']
-        )
-    )
 
     mlflow_init_status, mlflow_run = {{cookiecutter.src_package_name_short}}.general_utils.mlflow_init(
         args["mlflow_tracking_uri"], args["mlflow_exp_name"], 
         args["mlflow_run_name"], setup_mlflow=args["setup_mlflow"], 
         autolog=args["mlflow_autolog"], resume=args["resume"]
     )
+    
+    params = {
+        "n_estimators": args["n_estimators"],
+        "learning_rate": args["lr"],
+        "gamma": args["gamma"],
+        "max_depth": args["max_depth"],
+    }
+
+    if use_cuda := args["use_cuda"]:
+       params["device"] = cuda
+       params["tree_method"] = "hist"     
     {{cookiecutter.src_package_name_short}}.general_utils.mlflow_log(
         mlflow_init_status,
         "log_params",
-        params={
-            "learning_rate": args["lr"],
-            "train_batch_size": args["train_bs"],
-            "test_batch_size": args["test_bs"]
-        },
+        params=params,
     )
 
-    dataset = {{cookiecutter.src_package_name_short}}.data_prep.datasets.DummyDataset(args["data_dir_path"])
-
-    model = {{cookiecutter.src_package_name_short}}.modeling.models.DummyModel()
+    model = {{cookiecutter.src_package_name_short}}.modeling.models.Model()
     
-    for epoch in range(1, args["epochs"] + 1):
-        curr_train_loss = {{cookiecutter.src_package_name_short}}.modeling.utils.train(
-            mlflow_init_status, model, dataset, epoch, 
-            learning_rate=args["lr"],
-            batch_size=int(args["train_bs"])
-        )
-        curr_test_loss, curr_test_accuracy = {{cookiecutter.src_package_name_short}}.modeling.utils.test(
-            mlflow_init_status, model, dataset, epoch,
-            test_size=args["test_bs"]
-        )
+    ### Insert your model code
+    # train_score = model.train(params, X_train, y_train, mlflow_init_status)
+    # test_rmse = model.evaluate()
 
     {{cookiecutter.src_package_name_short}}.general_utils.mlflow_log(
         mlflow_init_status,
         "log_dict",
@@ -73,24 +66,27 @@
     )
 
     # Save metrics to artifact directory
     os.makedirs(args["artifact_dir_path"], exist_ok=True)
-    
+
     # Save training configuration
     artifact_path = os.path.join(
-        args["artifact_dir_path"], "output.txt"
+        args["artifact_dir_path"], "xgbreg.json"
     )
+    
+    # model.save_model(os.path.join(args["artifact_dir_path"], "xgbreg.json"))
+    
     with open(artifact_path, "w") as f:
         f.write('\n'.join([f'{x}: {args[x]}' for x in args]))
-    
+
     # Log artifacts to MLflow
     {{cookiecutter.src_package_name_short}}.general_utils.mlflow_log(
         mlflow_init_status,
         "log_artifact",
         local_path=artifact_path,
-        artifact_path="outputs"
+        artifact_path="model"
     )
-    
+
     if mlflow_init_status:
         artifact_uri = mlflow.get_artifact_uri()
         logger.info("Artifact URI: %s", artifact_uri)
         {{cookiecutter.src_package_name_short}}.general_utils.mlflow_log(
@@ -103,10 +99,12 @@
         mlflow.end_run()
     else:
         logger.info("Model training has completed.")
 
-    # Outputs for conf/train_model.yaml for hydra.sweeper.direction
-    return curr_test_loss, curr_test_accuracy
+    ## Uncomment return line
+    ## The function decorated with @hydra.main() returns a value that we want to
+    ## adjust base on hydra.sweeper.direction in conf/train_model.yaml
+    # return test_rmse
 
 
 if __name__ == "__main__":
     main()
