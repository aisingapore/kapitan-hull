--- {{cookiecutter.repo_name}}/src/batch_infer.py
+++ {{cookiecutter.repo_name}}/problem-templates/cv/src/batch_infer.py
@@ -1 +1 @@
-"""Script to conduct batch inferencing.
+"""Script to conduct batch inferencing on a directory of images.
@@ -8,0 +9,2 @@
+import torchvision
+from PIL import Image
@@ -34 +36,3 @@
-    loaded_model = {{cookiecutter.src_package_name_short}}.modeling.utils.load_model()
+    loaded_model, device = {{cookiecutter.src_package_name_short}}.modeling.utils.load_model(
+        args["model_path"], args["use_cuda"], args["use_mps"]
+    )
@@ -39 +43 @@
-    logger.info("Conducting inferencing on text files...")
+    logger.info("Conducting inferencing on image files...")
@@ -44 +48 @@
-    has_text = False # Checking if for loop is running
+    has_image = False # Checking if for loop is running
@@ -46,4 +50,8 @@
-    for text_file in glob.glob(glob_expr):
-        has_text = True
-        text = open(text_file).read()
-        pred_str = loaded_model.predict(text)
+    for image_file in glob.glob(glob_expr):
+        has_image = True
+        image = Image.open(image_file)
+        image = torchvision.transforms.functional.to_grayscale(image)
+        image = torchvision.transforms.functional.to_tensor(image)
+        output = loaded_model(image.unsqueeze(0).to(device))
+        pred = output.argmax(dim=1, keepdim=True)
+        pred_str = str(int(pred[0]))
@@ -56 +64 @@
-            "text_filepath": text_file,
+            "image_filepath": image_file,
@@ -64,3 +72,3 @@
-    if not has_text:
-        e = "Folder {} has no files to infer according to the given glob '{}'.".format(
-            os.path.abspath(args["input_data_dir"]), args["file_check_glob"]
+    if not has_image:
+        e = "Folder {} has no png files to infer.".format(
+            os.path.abspath(args["input_data_dir"])
